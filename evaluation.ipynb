{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e809426-a67f-4452-ab30-0824d2fc3438",
   "metadata": {},
   "source": [
    "## 4.1 Bestimmen Sie, welche Felder Ihrer Daten für Ihr Modell besonders aussagekräftig sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b9b7bf-e6f9-4f9b-be12-0101aa7f1b7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importances:\n",
      "                  Feature  Importance\n",
      "0                   score      0.6640\n",
      "1                  r-date      0.2144\n",
      "2                   users      0.0705\n",
      "3   No Online Multiplayer      0.0295\n",
      "4                 critics      0.0117\n",
      "5              1-2 Player      0.0053\n",
      "6                1 Player      0.0020\n",
      "7                 No info      0.0012\n",
      "8              1-4 Player      0.0008\n",
      "9             MP up to 16      0.0006\n",
      "10            MP up to 32      0.0000\n",
      "11            MP up to 30      0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, precision_score, recall_score\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"daten metacritic.csv\", sep=';')\n",
    "df['r-date'] = pd.to_datetime(df['r-date'], format='%d.%m.%Y')\n",
    "df['r-date'] = df['r-date'].astype('int64') // 10**9\n",
    "\n",
    "features = ['score', 'r-date', 'critics', 'users', '1 Player', '1-2 Player', 'No Online Multiplayer', 'MP up to 32', 'MP up to 30', 'MP up to 16', 'No info', '1-4 Player']\n",
    "X = df[features]\n",
    "y = df['user score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(gb_model, 'metacritic_model.joblib')\n",
    "\n",
    "sample_size = 200\n",
    "np.random.seed(None)\n",
    "random_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "np.save('sample_indices.npy', random_indices)\n",
    "\n",
    "sample_X = X_test.iloc[random_indices]\n",
    "sample_y = y_test.iloc[random_indices]\n",
    "sample_names = df.iloc[sample_X.index]['name']\n",
    "sample_platforms = df.iloc[sample_X.index]['platform']\n",
    "sample_scores = df.iloc[sample_X.index]['score']\n",
    "\n",
    "predictions = gb_model.predict(sample_X)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Game': sample_names,\n",
    "    'Platform': sample_platforms,\n",
    "    'Critic Score': sample_scores,\n",
    "    'Actual User Score': sample_y,\n",
    "    'Predicted User Score': predictions,\n",
    "    'Error': np.abs(sample_y - predictions)\n",
    "})\n",
    "\n",
    "\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "importances = gb_model.feature_importances_\n",
    "\n",
    "# DataFrame mit Feature-Namen und deren Wichtigkeit\n",
    "feat_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Absteigend sortieren\n",
    "feat_df = feat_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Ausgabe\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feat_df.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479cc1c-fa5b-4916-afba-1e95502230e7",
   "metadata": {},
   "source": [
    "## 4.2 Wählen Sie eine geeignete Messmetrik für Ihr Modell und berechnen Sie sie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93aa6976-68cd-406d-a069-11f685568429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions vs Actual Values:\n",
      "                                                Game      Platform  \\\n",
      "485                                    Soldier Elite            PC   \n",
      "14720            Phantasy Star Online Episode I & II      GameCube   \n",
      "6062                                    Akiba's Beat  PlayStation4   \n",
      "7360   LEGO Pirates of the Caribbean: The Video Game           3DS   \n",
      "3245                                       Sparkle 2  PlayStation4   \n",
      "...                                              ...           ...   \n",
      "168                                          Randall  PlayStation4   \n",
      "14268                 Trauma Center: Under the Knife            DS   \n",
      "14547                       Worms Forts: Under Siege          Xbox   \n",
      "9489                    DeathSpank: Thongs of Virtue            PC   \n",
      "12393                                   Planet Alpha            PC   \n",
      "\n",
      "       Critic Score  Actual User Score  Predicted User Score  Error  \n",
      "485              40                3.6                  5.32   1.72  \n",
      "14720            85                8.4                  8.29   0.11  \n",
      "6062             55                6.8                  5.83   0.97  \n",
      "7360             71                7.1                  7.05   0.05  \n",
      "3245             66                6.0                  6.59   0.59  \n",
      "...             ...                ...                   ...    ...  \n",
      "168              38                2.5                  4.40   1.90  \n",
      "14268            81                8.3                  8.14   0.16  \n",
      "14547            67                8.3                  7.09   1.21  \n",
      "9489             78                7.5                  7.50   0.00  \n",
      "12393            72                7.9                  6.94   0.96  \n",
      "\n",
      "[200 rows x 6 columns]\n",
      "\n",
      "Mean Absolute Error (MAE) auf Testset: 0.753\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"daten metacritic.csv\", sep=';')\n",
    "df['r-date'] = pd.to_datetime(df['r-date'], format='%d.%m.%Y')\n",
    "df['r-date'] = df['r-date'].astype('int64') // 10**9\n",
    "\n",
    "features = ['score', 'r-date', 'critics', 'users', '1 Player', '1-2 Player', 'No Online Multiplayer', 'MP up to 32', 'MP up to 30', 'MP up to 16', 'No info', '1-4 Player']\n",
    "X = df[features]\n",
    "y = df['user score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "joblib.dump(gb_model, 'metacritic_model.joblib')\n",
    "\n",
    "sample_size = 200\n",
    "np.random.seed(None)\n",
    "random_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "np.save('sample_indices.npy', random_indices)\n",
    "\n",
    "sample_X = X_test.iloc[random_indices]\n",
    "sample_y = y_test.iloc[random_indices]\n",
    "sample_names = df.iloc[sample_X.index]['name']\n",
    "sample_platforms = df.iloc[sample_X.index]['platform']\n",
    "sample_scores = df.iloc[sample_X.index]['score']\n",
    "\n",
    "predictions = gb_model.predict(sample_X)\n",
    "\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Game': sample_names,\n",
    "    'Platform': sample_platforms,\n",
    "    'Critic Score': sample_scores,\n",
    "    'Actual User Score': sample_y,\n",
    "    'Predicted User Score': predictions,\n",
    "    'Error': np.abs(sample_y - predictions)\n",
    "})\n",
    "\n",
    "print(\"\\nSample Predictions vs Actual Values:\")\n",
    "print(comparison.round(2))\n",
    "\n",
    "y_test_pred = gb_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"\\nMean Absolute Error (MAE) auf Testset: {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51efe2d0-fe97-41f4-9d6c-b02516b2aa9b",
   "metadata": {},
   "source": [
    "## 4.3 Wählen Sie geeignete Bedingungen und erstellen Sie eine Wahrheitsmatrix für Ihr Modell. Berechnen Sie darüber hinaus Sensitivität und Spezifizität."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcf3186-0462-4b2e-bc38-046a22699f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[1027  297]\n",
      " [ 580 1428]]\n",
      "Precision: 0.828\n",
      "Recall:    0.711\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, confusion_matrix, precision_score, recall_score\n",
    "import joblib\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv(\"daten metacritic.csv\", sep=';')\n",
    "df['r-date'] = pd.to_datetime(df['r-date'], format='%d.%m.%Y')\n",
    "df['r-date'] = df['r-date'].astype('int64') // 10**9\n",
    "\n",
    "features = ['score', 'r-date', 'critics', 'users', '1 Player', '1-2 Player', 'No Online Multiplayer', 'MP up to 32', 'MP up to 30', 'MP up to 16', 'No info', '1-4 Player']\n",
    "X = df[features]\n",
    "y = df['user score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(gb_model, 'metacritic_model.joblib')\n",
    "\n",
    "sample_size = 200\n",
    "np.random.seed(None)\n",
    "random_indices = np.random.choice(len(X_test), sample_size, replace=False)\n",
    "np.save('sample_indices.npy', random_indices)\n",
    "\n",
    "sample_X = X_test.iloc[random_indices]\n",
    "sample_y = y_test.iloc[random_indices]\n",
    "sample_names = df.iloc[sample_X.index]['name']\n",
    "sample_platforms = df.iloc[sample_X.index]['platform']\n",
    "sample_scores = df.iloc[sample_X.index]['score']\n",
    "\n",
    "predictions = gb_model.predict(sample_X)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Game': sample_names,\n",
    "    'Platform': sample_platforms,\n",
    "    'Critic Score': sample_scores,\n",
    "    'Actual User Score': sample_y,\n",
    "    'Predicted User Score': predictions,\n",
    "    'Error': np.abs(sample_y - predictions)\n",
    "})\n",
    "\n",
    "\n",
    "# Aufgabe 4.3\n",
    "threshold = 7.0\n",
    "y_true_bin = (y_test >= threshold).astype(int)\n",
    "y_pred_bin = (y_test_pred >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_true_bin, y_pred_bin)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "prec = precision_score(y_true_bin, y_pred_bin)\n",
    "rec  = recall_score(y_true_bin, y_pred_bin)\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall:    {rec:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5c2b4-dcab-4d76-ba58-f586df51c6ed",
   "metadata": {},
   "source": [
    "## 4.4 Fassen Sie in 50 bis 100 Wörtern zusammen, wie gut Ihr Modell funktioniert, und stellen Sie Hypothesen auf, warum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e8122-a2d4-462f-bb3c-f605c00a28c2",
   "metadata": {},
   "source": [
    "Das Modell liefert in der Praxis solide Vorhersagen für die Nutzerbewertungen: Es erkennt zuverlässig gut bewertete Spiele und übersieht nur selten hoch gelobte Titel. Kritikerbewertungen und das Veröffentlichungsdatum haben den grössten Einfluss. Ich vermute, dass es daran liegt, dass professionelle Rezensionen näher an den Erwartungen der Spieler liegen und dass aktuelle Titel stärker im Gespräch sind und daher besser repräsentiert werden. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
